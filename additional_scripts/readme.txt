subtraction_second_baseline.py - вторая корректировка на бейзлайн (полную версию двух шагового метода корректировка на БЛ можно посмотеть в probability_learning/function.py, была заменена на одношаговыю с ранним логарифмированием, т.е. оба метода дают одинаковый результат, но одношаговую проще объяснять) 

check_csv.py - сравнение двух таблиц .csv


main_with_average.py - получает усреденнные данные для определенной частотного диапазона (парамент MNE multitaper average = True). Использует функцию make_beta_signal из make_freq_with_average.py

make_freq_early_log.py функция make_beta_signal для получения эпох в определенном частотным диапазоне, с ранним логарифмированием, такая же функция есть в probability_learning/function.py


evoked_ave_between_runs_and_fb.py - по итогу скрипта получаем усредненные данные внутри каждого испытуемого. Усреденение происходит средствами MNE: сначала усредняем данные внутри фидбека (и внутри блока (run)), т.е. из эпох получаем evoked. Затем собираем список evoked для каждого испытуемого (должно получаеться от 0 до 12, по количеству блоков 6, каждый блок разделен на 2 фид бека - 12), затем получаем grand_averange из списка evoked, с помощью функции mne.grand_averege()

evoked_ave_between_runs_and_fb_var2.py - по итогу скрипта получаем усредненные данные внутри каждого испытуемого. Вначале объединяем данные для разных фидбэков внутри блока, затем усредняем их с помощью mean. Далее объединяем данные для испытуемого в один массив и усредняем их с помощью mean, делаем Evoked с помощью донора, сохраняем.

evoked_ave_between_runs_and_fb_var3_average.py - по итогу скрипта получаем усредненные данные внутри каждого испытуемого. Данные изначально усредены (парамент MNE multitaper average = True), сохраняем.

grand_average_v1.py - average the values using mne.grand_average() (average var. 1)
